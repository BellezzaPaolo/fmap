{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom datetime import datetime\n\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow import keras as tfk\nfrom tensorflow.keras import layers as tfkl\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"Keras version: {tfk.__version__}\")\nprint(f\"GPU devices: {len(tf.config.list_physical_devices('GPU'))}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ⏳ Load the Data","metadata":{}},{"cell_type":"code","source":"data = np.load(\"mars_for_students.npz\")\n\ntraining_set = data[\"training_set\"]\nX_train = training_set[:, 0]\ny_train = training_set[:, 1]\n\nX_test = data[\"test_set\"]\n\nprint(f\"Training X shape: {X_train.shape}\")\nprint(f\"Training y shape: {y_train.shape}\")\nprint(f\"Test X shape: {X_test.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Data exploration","metadata":{}},{"cell_type":"code","source":"def plot_pairs(data, labels, index=None):\n    if index == None:\n        index = np.random.randint(0,len(data))\n    fig, axes = plt.subplots(1, 2, figsize=(16,4))\n    axes[0].set_title(\"Image\")\n    axes[0].imshow(data[index])\n    axes[1].set_title(\"Mask\")\n    colored_image = display_color_mapped_image_continuous(labels[index])\n    axes[1].imshow(np.squeeze(colored_image))\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preprocessing data","metadata":{}},{"cell_type":"code","source":"# Add color channel and rescale pixels between 0 and 1\nX_train = X_train[..., np.newaxis] / 255.0\nX_test = X_test[..., np.newaxis] / 255.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🛠️ Train and Save the Model","metadata":{}},{"cell_type":"code","source":"input_shape = X_train.shape[1:]\nnum_classes = len(np.unique(y_train))\n\nprint(f\"Input shape: {input_shape}\")\nprint(f\"Number of classes: {num_classes}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Building blocks","metadata":{}},{"cell_type":"code","source":"def basic_cnn_block(x, filters=32, kernel_size=3, padding='same',\n                    downsample=True, activation='relu', stack=2, name='basic'):\n    # Define a basic CNN block with Conv -> ReLU -> MaxPool pattern\n    for i in range(stack):\n        x = tfkl.SeparableConv2D(filters, kernel_size, padding=padding, name=f'{name}_conv_{i}')(x)\n        x = tfkl.Activation(activation, name=f'{name}_act_{i}')(x)\n        x = tfkl.BatchNormalization(name=f'{name}_bn_{i}')(x)\n\n    # Add MaxPooling layer if downsample is True\n    if downsample:\n        x = tfkl.MaxPooling2D(2, name=f'{name}_pool')(x)\n    return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def inception_module(x, filters_1x1=32, filters_3x3_reduce=48, filters_3x3=64,\n                     filters_5x5_reduce=8, filters_5x5=26,\n                     stack=2, name='inception', padding='same', activation='relu'):\n    # Initialize lists to collect outputs from each branch\n    outputs = []\n\n    # Define a basic CNN block with Conv -> ReLU -> MaxPool pattern\n    for i in range(stack):\n        # 1x1 convolution\n        conv_1 = tfkl.SeparableConv2D(filters_1x1, 1, padding=padding, name=f'{name}_conv_1x1_{i}')(x)\n        conv_1 = tfkl.Activation(activation, name=f'{name}_act_1x1_{i}')(conv_1)\n        conv_1 = tfkl.BatchNormalization(name=f'{name}_bn_1x1_{i}')(conv_1)\n        outputs.append(conv_1)\n\n        # 3x3 convolution\n        conv_3 = tfkl.SeparableConv2D(filters_3x3_reduce, 1, padding=padding, name=f'{name}_conv_3x3_reduce_{i}')(x)\n        conv_3 = tfkl.SeparableConv2D(filters_3x3, 3, padding=padding, name=f'{name}_conv_3x3_{i}')(conv_3)\n        conv_3 = tfkl.Activation(activation, name=f'{name}_act_3x3_{i}')(conv_3)\n        conv_3 = tfkl.BatchNormalization(name=f'{name}_bn_3x3_{i}')(conv_3)\n        outputs.append(conv_3)\n\n        # 5x5 convolution\n        conv_5 = tfkl.SeparableConv2D(filters_5x5_reduce, 1, padding=padding, name=f'{name}_conv_5x5_reduce_{i}')(x)\n        conv_5 = tfkl.SeparableConv2D(filters_5x5, 5, padding=padding, name=f'{name}_conv_5x5_{i}')(conv_5)\n        conv_5 = tfkl.Activation(activation, name=f'{name}_act_5x5_{i}')(conv_5)\n        conv_5 = tfkl.BatchNormalization(name=f'{name}_bn_5x5_{i}')(conv_5)\n        outputs.append(conv_5)\n\n        # Average Pooling\n        avg_pool = tfkl.AveragePooling2D(3, strides=1, padding='same', name=f'{name}_avg_pool_{i}')(x)\n        conv_avg = tfkl.SeparableConv2D(filters_1x1, 1, padding=padding, name=f'{name}_conv_avg_{i}')(avg_pool)\n        conv_avg = tfkl.Activation(activation, name=f'{name}_act_avg_{i}')(conv_avg)\n        conv_avg = tfkl.BatchNormalization(name=f'{name}_bn_avg_{i}')(conv_avg)\n        outputs.append(conv_avg)\n\n    # Concatenate outputs from all branches\n    x = tfkl.Concatenate(name=f'{name}_concat')(outputs)\n\n    return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def unet_block(input_tensor, filters, kernel_size=3, activation='relu', stack=2, name=''):\n\n    x = input_tensor\n    for i in range(stack):\n        x = tfkl.Conv2D(filters, kernel_size=3, padding='same', name=name+'conv'+str(i+1))(x)\n        x = tfkl.BatchNormalization(name=name+'bn'+str(i+1))(x)\n        x = tfkl.Activation(activation, name=name+'activation'+str(i+1))(x)\n\n    return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model Creation","metadata":{}},{"cell_type":"code","source":"def create_model(input_shape=input_shape, num_classes=num_classes, seed=seed):\n    tf.random.set_seed(seed)\n    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n\n    # First Downsampling\n    down_block_1 = unet_block(input_layer, 64, name='down_block1_')\n    d1 = tfkl.MaxPooling2D()(down_block_1)\n\n    # Second Downsampling\n    down_block_2 = unet_block(d1, 128, name='down_block2_')\n    d2 = tfkl.MaxPooling2D()(down_block_2)\n\n    # Third Downsampling\n    down_block_3 = unet_block(d2, 256, name='down_block3_')\n    d3 = tfkl.MaxPooling2D()(down_block_3)\n\n    # Fourth Downsampling\n    down_block_4 = unet_block(d3, 512, name='down_block4_')\n    d4 = tfkl.MaxPooling2D()(down_block_4)\n\n    # Bottleneck\n    bottleneck = unet_block(d4, 512, name='bottleneck')\n\n    # First Upsampling\n    u1 = tfkl.UpSampling2D()(bottleneck)\n    u1 = tfkl.Add(name='add1')([u1,down_block_4])\n    u1 = unet_block(u1, 256, name='up_block1_')\n\n    # Second Upsampling\n    u2 = tfkl.UpSampling2D()(u1)\n    u2 = tfkl.Add(name='add2')([u2,down_block_3])\n    u2 = unet_block(u2, 128, name='up_block2_')\n\n    # Third Upsampling\n    u3 = tfkl.UpSampling2D()(u2)\n    u3 = tfkl.Add(name='add3')([u3,down_block_2])\n    u3 = unet_block(u3, 64, name='up_block3_')\n\n    # Forth Upsampling\n    u4 = tfkl.UpSampling2D()(u3)\n    u4 = tfkl.Add(name='add4')([u4,down_block_1])\n    u4 = unet_block(u4, 64, name='up_block4_')\n\n    # Output Layer\n    output_layer = tf.keras.layers.Conv2D(num_classes, kernel_size=3, padding='same', activation=\"softmax\", name='output_layer')(u4)\n\n    model = tfk.Model(inputs=input_layer, outputs=output_layer)\n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Minimal working Net","metadata":{}},{"cell_type":"code","source":"inputs = tfkl.Input(shape=input_shape)\nx = tfkl.Conv2D(filters=num_classes, kernel_size=(1, 1), activation=\"softmax\")(inputs)\nmodel = tfk.Model(inputs=inputs, outputs=x, name=\"minimal_working_net\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model compilation","metadata":{}},{"cell_type":"code","source":"model = create_model()\n\n# Define the MeanIoU ignoring the background class\nmean_iou = tfk.metrics.MeanIoU(num_classes=num_classes, ignore_class=0, sparse_y_pred=False)\n\nmodel.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[mean_iou])\n\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Fit the model","metadata":{}},{"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"timestep_str = datetime.now().strftime(\"%y%m%d_%H%M%S\")\nmodel_filename = f\"model_{timestep_str}.keras\"\nmodel.save(model_filename)\ndel model\n\nprint(f\"Model saved to {model_filename}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 📊 Prepare Your Submission\n\nIn our Kaggle competition, submissions are made as `csv` files. To create a proper `csv` file, you need to flatten your predictions and include an `id` column as the first column of your dataframe. To maintain consistency between your results and our solution, please avoid shuffling the test set. The code below demonstrates how to prepare the `csv` file from your model predictions.","metadata":{}},{"cell_type":"markdown","source":"### Re-load the model","metadata":{}},{"cell_type":"code","source":"# If model_filename is not defined, load the most recent model from Google Drive\nif \"model_filename\" not in globals() or model_filename is None:\n    files = [f for f in os.listdir('.') if os.path.isfile(f) and f.startswith('model_') and f.endswith('.keras')]\n    files.sort(key=lambda x: os.path.getmtime(x), reverse=True)\n    if files:\n        model_filename = files[0]\n    else:\n        raise FileNotFoundError(\"No model files found in the current directory.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = tfk.models.load_model(model_filename)\nprint(f\"Model loaded from {model_filename}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Predict and save","metadata":{}},{"cell_type":"code","source":"def y_to_df(y) -> pd.DataFrame:\n    \"\"\"Converts segmentation predictions into a DataFrame format for Kaggle.\"\"\"\n    n_samples = len(y)\n    y_flat = y.reshape(n_samples, -1)\n    df = pd.DataFrame(y_flat)\n    df[\"id\"] = np.arange(n_samples)\n    cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n    return df[cols]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds = model.predict(X_test)\npreds = np.argmax(preds, axis=-1)\nprint(f\"Predictions shape: {preds.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create and download the csv submission file\ntimestep_str = model_filename.replace(\"model_\", \"\").replace(\".keras\", \"\")\nsubmission_filename = f\"submission_{timestep_str}.csv\"\nsubmission_df = y_to_df(preds)\nsubmission_df.to_csv(submission_filename, index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}