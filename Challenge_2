{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom datetime import datetime\n\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow import keras as tfk\nfrom tensorflow.keras import layers as tfkl\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"Keras version: {tfk.__version__}\")\nprint(f\"GPU devices: {len(tf.config.list_physical_devices('GPU'))}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## â³ Load the Data","metadata":{}},{"cell_type":"code","source":"data = np.load(\"mars_for_students.npz\")\n\ntraining_set = data[\"training_set\"]\nX_train = training_set[:, 0]\ny_train = training_set[:, 1]\n\nX_test = data[\"test_set\"]\n\nprint(f\"Training X shape: {X_train.shape}\")\nprint(f\"Training y shape: {y_train.shape}\")\nprint(f\"Test X shape: {X_test.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Data exploration","metadata":{}},{"cell_type":"code","source":"def plot_pairs(data, labels, index=None):\n    if index == None:\n        index = np.random.randint(0,len(data))\n    fig, axes = plt.subplots(1, 2, figsize=(16,4))\n    axes[0].set_title(\"Image\")\n    axes[0].imshow(data[index])\n    axes[1].set_title(\"Mask\")\n    colored_image = display_color_mapped_image_continuous(labels[index])\n    axes[1].imshow(np.squeeze(colored_image))\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preprocessing data","metadata":{}},{"cell_type":"code","source":"# Add color channel and rescale pixels between 0 and 1\nX_train = X_train[..., np.newaxis] / 255.0\nX_test = X_test[..., np.newaxis] / 255.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ðŸ› ï¸ Train and Save the Model","metadata":{}},{"cell_type":"code","source":"input_shape = X_train.shape[1:]\nnum_classes = len(np.unique(y_train))\n\nprint(f\"Input shape: {input_shape}\")\nprint(f\"Number of classes: {num_classes}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Building blocks","metadata":{}},{"cell_type":"code","source":"def basic_cnn_block(x, filters=32, kernel_size=3, padding='same',\n                    downsample=True, activation='relu', stack=2, name='basic'):\n    # Define a basic CNN block with Conv -> ReLU -> MaxPool pattern\n    for i in range(stack):\n        x = tfkl.SeparableConv2D(filters, kernel_size, padding=padding, name=f'{name}_conv_{i}')(x)\n        x = tfkl.Activation(activation, name=f'{name}_act_{i}')(x)\n        x = tfkl.BatchNormalization(name=f'{name}_bn_{i}')(x)\n\n    # Add MaxPooling layer if downsample is True\n    if downsample:\n        x = tfkl.MaxPooling2D(2, name=f'{name}_pool')(x)\n    return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def inception_module(x, filters_1x1=32, filters_3x3_reduce=48, filters_3x3=64,\n                     filters_5x5_reduce=8, filters_5x5=26,\n                     stack=2, name='inception', padding='same', activation='relu'):\n    # Initialize lists to collect outputs from each branch\n    outputs = []\n\n    # Define a basic CNN block with Conv -> ReLU -> MaxPool pattern\n    for i in range(stack):\n        # 1x1 convolution\n        conv_1 = tfkl.SeparableConv2D(filters_1x1, 1, padding=padding, name=f'{name}_conv_1x1_{i}')(x)\n        conv_1 = tfkl.Activation(activation, name=f'{name}_act_1x1_{i}')(conv_1)\n        conv_1 = tfkl.BatchNormalization(name=f'{name}_bn_1x1_{i}')(conv_1)\n        outputs.append(conv_1)\n\n        # 3x3 convolution\n        conv_3 = tfkl.SeparableConv2D(filters_3x3_reduce, 1, padding=padding, name=f'{name}_conv_3x3_reduce_{i}')(x)\n        conv_3 = tfkl.SeparableConv2D(filters_3x3, 3, padding=padding, name=f'{name}_conv_3x3_{i}')(conv_3)\n        conv_3 = tfkl.Activation(activation, name=f'{name}_act_3x3_{i}')(conv_3)\n        conv_3 = tfkl.BatchNormalization(name=f'{name}_bn_3x3_{i}')(conv_3)\n        outputs.append(conv_3)\n\n        # 5x5 convolution\n        conv_5 = tfkl.SeparableConv2D(filters_5x5_reduce, 1, padding=padding, name=f'{name}_conv_5x5_reduce_{i}')(x)\n        conv_5 = tfkl.SeparableConv2D(filters_5x5, 5, padding=padding, name=f'{name}_conv_5x5_{i}')(conv_5)\n        conv_5 = tfkl.Activation(activation, name=f'{name}_act_5x5_{i}')(conv_5)\n        conv_5 = tfkl.BatchNormalization(name=f'{name}_bn_5x5_{i}')(conv_5)\n        outputs.append(conv_5)\n\n        # Average Pooling\n        avg_pool = tfkl.AveragePooling2D(3, strides=1, padding='same', name=f'{name}_avg_pool_{i}')(x)\n        conv_avg = tfkl.SeparableConv2D(filters_1x1, 1, padding=padding, name=f'{name}_conv_avg_{i}')(avg_pool)\n        conv_avg = tfkl.Activation(activation, name=f'{name}_act_avg_{i}')(conv_avg)\n        conv_avg = tfkl.BatchNormalization(name=f'{name}_bn_avg_{i}')(conv_avg)\n        outputs.append(conv_avg)\n\n    # Concatenate outputs from all branches\n    x = tfkl.Concatenate(name=f'{name}_concat')(outputs)\n\n    return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the Residual block with configurable parameters\ndef residual_block(x, filters, kernel_size=3, padding='same',\n                   downsample=True, activation='relu', stack=2, name='residual'):\n\n    for s in range(stack):\n        # Save input for skip connection\n        skip = x\n\n        # First convolutional block with Batch Normalisation and activation\n        x = tfkl.Conv2D(filters, kernel_size, padding=padding, name=f'{name}_conv1_{s}')(x)\n        x = tfkl.BatchNormalization(name=f'{name}_bn1_{s}')(x)\n        x = tfkl.Activation(activation, name=f'{name}_act1_{s}')(x)\n\n        # Second convolutional block\n        x = tfkl.Conv2D(filters, kernel_size, padding=padding, name=f'{name}_conv2_{s}')(x)\n        x = tfkl.BatchNormalization(name=f'{name}_bn2_{s}')(x)\n\n        # Adjust skip connection dimension if needed\n        if skip.shape[-1] != filters:\n            skip = tfkl.Conv2D(filters, 1, padding=padding, name=f'{name}_proj_{s}')(skip)\n            skip = tfkl.BatchNormalization(name=f'{name}_proj_bn_{s}')(skip)\n\n        # Add skip connection and apply activation\n        x = tfkl.Add(name=f'{name}_add_{s}')([x, skip])\n        x = tfkl.Activation(activation, name=f'{name}_act2_{s}')(x)\n\n    # Optional downsampling\n    if downsample:\n        x = tfkl.MaxPooling2D(2, name=f'{name}_pool')(x)\n\n    return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the SENet block with configurable parameters\ndef senet_block(x, filters, kernel_size=3, padding='same',\n                downsample=True, activation='relu', stack=2, name='senet'):\n\n    for s in range(stack):\n        # Main convolutional path\n        x = tfkl.Conv2D(filters, kernel_size, padding=padding,\n                        use_bias=False, name=f'{name}_conv_{s}')(x)\n        x = tfkl.BatchNormalization(name=f'{name}_bn_{s}')(x)\n        x = tfkl.Activation(activation, name=f'{name}_act_{s}')(x)\n\n        # Squeeze-and-Excitation (SE) module\n        channels = x.shape[-1]\n\n        # Squeeze step\n        se = tfkl.GlobalAveragePooling2D(name=f'{name}_squeeze_{s}')(x)\n\n        # Excitation step\n        se = tfkl.Dense(channels // 16, activation=activation, name=f'{name}_dense1_{s}')(se)\n        se = tfkl.Dense(channels, activation='sigmoid', name=f'{name}_dense2_{s}')(se)\n\n        # Scaling of the output with SE activation\n        se = tfkl.Reshape((1, 1, channels))(se)\n        x = tfkl.Multiply(name=f'{name}_scale_{s}')([x, se])\n\n    # Optional downsampling\n    if downsample:\n        x = tfkl.MaxPooling2D(2, name=f'{name}_pool')(x)\n\n    return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the MobileNetV3 block with configurable parameters\ndef mobilenetv3_block(x, filters, kernel_size=3, padding='same',\n                      downsample=True, activation='relu', stack=1, name='mobilev3'):\n\n    # Define h-swish activation function\n    def h_swish(x):\n        return x * tf.nn.relu6(x + 3.0) / 6.0\n\n    # Select activation function\n    activation_fn = tf.nn.relu if activation == 'relu' else h_swish\n\n    for s in range(stack):\n        input_channels = x.shape[-1]\n        residual = x\n\n        # Set expansion factor based on channel dimensions\n        expansion_factor = 1 if input_channels == filters else 6\n        expanded_channels = input_channels * expansion_factor\n\n        # Expansion phase\n        if expansion_factor != 1:\n            x = tfkl.Conv2D(expanded_channels, 1, padding=padding, use_bias=False, name=f'{name}_expand_{s}')(x)\n            x = tfkl.BatchNormalization(name=f'{name}_bn1_{s}')(x)\n            x = tfkl.Activation(activation_fn, name=f'{name}_act1_{s}')(x)\n\n        # Depthwise convolution with optional downsampling\n        stride = 2 if (downsample and s == 0) else 1\n        x = tfkl.DepthwiseConv2D(kernel_size, strides=stride, padding=padding, use_bias=False, name=f'{name}_depthwise_{s}')(x)\n        x = tfkl.BatchNormalization(name=f'{name}_bn2_{s}')(x)\n        x = tfkl.Activation(activation_fn, name=f'{name}_act2_{s}')(x)\n\n        # Squeeze-and-Excitation module\n        se_channels = max(1, expanded_channels // 4)\n        se = tfkl.GlobalAveragePooling2D(name=f'{name}_se_pool_{s}')(x)\n        se = tfkl.Reshape((1, 1, expanded_channels))(se)\n        se = tfkl.Conv2D(se_channels, 1, activation='relu', name=f'{name}_se_reduce_{s}')(se)\n        se = tfkl.Conv2D(expanded_channels, 1, activation='hard_sigmoid', name=f'{name}_se_expand_{s}')(se)\n        x = tfkl.Multiply(name=f'{name}_se_excite_{s}')([x, se])\n\n        # Projection phase to desired filter dimension\n        x = tfkl.Conv2D(filters, 1, padding=padding, use_bias=False, name=f'{name}_project_{s}')(x)\n        x = tfkl.BatchNormalization(name=f'{name}_bn3_{s}')(x)\n\n        # Add skip connection if applicable\n        if stride == 1 and input_channels == filters:\n            x = tfkl.Add(name=f'{name}_add_{s}')([residual, x])\n\n    return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def unet_block(input_tensor, filters, kernel_size=3, activation='relu', stack=2, name=''):\n\n    x = input_tensor\n    for i in range(stack):\n        x = tfkl.Conv2D(filters, kernel_size=3, padding='same', name=name+'conv'+str(i+1))(x)\n        x = tfkl.BatchNormalization(name=name+'bn'+str(i+1))(x)\n        x = tfkl.Activation(activation, name=name+'activation'+str(i+1))(x)\n\n    return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model Creation","metadata":{}},{"cell_type":"code","source":"def create_model(input_shape=input_shape, num_classes=num_classes, seed=seed):\n    tf.random.set_seed(seed)\n    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n\n    # First Downsampling\n    down_block_1 = unet_block(input_layer, 64, name='down_block1_')\n    d1 = tfkl.MaxPooling2D()(down_block_1)\n\n    # Second Downsampling\n    down_block_2 = unet_block(d1, 128, name='down_block2_')\n    d2 = tfkl.MaxPooling2D()(down_block_2)\n\n    # Third Downsampling\n    down_block_3 = unet_block(d2, 256, name='down_block3_')\n    d3 = tfkl.MaxPooling2D()(down_block_3)\n\n    # Fourth Downsampling\n    down_block_4 = unet_block(d3, 512, name='down_block4_')\n    d4 = tfkl.MaxPooling2D()(down_block_4)\n\n    # Bottleneck\n    bottleneck = unet_block(d4, 512, name='bottleneck')\n\n    # First Upsampling\n    u1 = tfkl.UpSampling2D()(bottleneck)\n    u1 = tfkl.Add(name='add1')([u1,down_block_4])\n    u1 = unet_block(u1, 256, name='up_block1_')\n\n    # Second Upsampling\n    u2 = tfkl.UpSampling2D()(u1)\n    u2 = tfkl.Add(name='add2')([u2,down_block_3])\n    u2 = unet_block(u2, 128, name='up_block2_')\n\n    # Third Upsampling\n    u3 = tfkl.UpSampling2D()(u2)\n    u3 = tfkl.Add(name='add3')([u3,down_block_2])\n    u3 = unet_block(u3, 64, name='up_block3_')\n\n    # Forth Upsampling\n    u4 = tfkl.UpSampling2D()(u3)\n    u4 = tfkl.Add(name='add4')([u4,down_block_1])\n    u4 = unet_block(u4, 64, name='up_block4_')\n\n    # Output Layer\n    output_layer = tf.keras.layers.Conv2D(num_classes, kernel_size=3, padding='same', activation=\"softmax\", name='output_layer')(u4)\n\n    model = tfk.Model(inputs=input_layer, outputs=output_layer)\n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Minimal working Net","metadata":{}},{"cell_type":"code","source":"inputs = tfkl.Input(shape=input_shape)\nx = tfkl.Conv2D(filters=num_classes, kernel_size=(1, 1), activation=\"softmax\")(inputs)\nmodel = tfk.Model(inputs=inputs, outputs=x, name=\"minimal_working_net\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model compilation","metadata":{}},{"cell_type":"code","source":"model = create_model()\n\n# Define the MeanIoU ignoring the background class\nmean_iou = tfk.metrics.MeanIoU(num_classes=num_classes, ignore_class=0, sparse_y_pred=False)\n\nmodel.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[mean_iou])\n\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Fit the model","metadata":{}},{"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"timestep_str = datetime.now().strftime(\"%y%m%d_%H%M%S\")\nmodel_filename = f\"model_{timestep_str}.keras\"\nmodel.save(model_filename)\ndel model\n\nprint(f\"Model saved to {model_filename}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ðŸ“Š Prepare Your Submission\n\nIn our Kaggle competition, submissions are made as `csv` files. To create a proper `csv` file, you need to flatten your predictions and include an `id` column as the first column of your dataframe. To maintain consistency between your results and our solution, please avoid shuffling the test set. The code below demonstrates how to prepare the `csv` file from your model predictions.","metadata":{}},{"cell_type":"markdown","source":"### Re-load the model","metadata":{}},{"cell_type":"code","source":"# If model_filename is not defined, load the most recent model from Google Drive\nif \"model_filename\" not in globals() or model_filename is None:\n    files = [f for f in os.listdir('.') if os.path.isfile(f) and f.startswith('model_') and f.endswith('.keras')]\n    files.sort(key=lambda x: os.path.getmtime(x), reverse=True)\n    if files:\n        model_filename = files[0]\n    else:\n        raise FileNotFoundError(\"No model files found in the current directory.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = tfk.models.load_model(model_filename)\nprint(f\"Model loaded from {model_filename}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Predict and save","metadata":{}},{"cell_type":"code","source":"def y_to_df(y) -> pd.DataFrame:\n    \"\"\"Converts segmentation predictions into a DataFrame format for Kaggle.\"\"\"\n    n_samples = len(y)\n    y_flat = y.reshape(n_samples, -1)\n    df = pd.DataFrame(y_flat)\n    df[\"id\"] = np.arange(n_samples)\n    cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n    return df[cols]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds = model.predict(X_test)\npreds = np.argmax(preds, axis=-1)\nprint(f\"Predictions shape: {preds.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create and download the csv submission file\ntimestep_str = model_filename.replace(\"model_\", \"\").replace(\".keras\", \"\")\nsubmission_filename = f\"submission_{timestep_str}.csv\"\nsubmission_df = y_to_df(preds)\nsubmission_df.to_csv(submission_filename, index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}